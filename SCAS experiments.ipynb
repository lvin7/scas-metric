{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9307fce-8287-404b-8316-7e008adba573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.optimize import brentq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e500029-ea10-44f6-b2d2-7aebc3f78f41",
   "metadata": {},
   "source": [
    "# Defining the metric (adaptive threshold-based)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a73ca7-8f98-44a9-9910-2ddd5ac46035",
   "metadata": {},
   "source": [
    "Let the absolute residuals be defined as:\n",
    "\n",
    "$$\n",
    "\\varepsilon_i = \\left| y_i^{\\text{true}} - y_i^{\\text{sim}} \\right|\n",
    "$$\n",
    "\n",
    "We define SCAS as the solution to the fixed-point equation, denoted as $\\tau$:\n",
    "\n",
    "$$\n",
    "\\tau = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbf{1} \\left\\{ \\varepsilon_i < (1 - \\tau) \\cdot \\sigma \\right\\}\n",
    "$$\n",
    "\n",
    "where $\\sigma $ is a scale parameter (e.g., standard deviation of $y^{\\text{true}}$), and $\\mathbf{1}(\\cdot)$ is the indicator function.\n",
    "r function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda3f72-55c1-4132-8111-a1c735829ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mad(x):\n",
    "    return np.median(np.abs(x - np.median(x)))\n",
    "\n",
    "def _scale_y(y, prefer='sd'):\n",
    "    \"\"\"Return scale of y; prefer 'sd' but fall back to MAD if needed.\"\"\"\n",
    "    if prefer == 'mad':\n",
    "        return 1.4826 * _mad(y)\n",
    "    s = np.std(y, ddof=1)\n",
    "    if not np.isfinite(s) or s <= 0:\n",
    "        s = 1.4826 * _mad(y)\n",
    "    # final guard:\n",
    "    if not np.isfinite(s) or s <= 0:\n",
    "        s = 1.0\n",
    "    return s\n",
    "\n",
    "def SCAS(y_true, y_pred, tol=1e-6, prefer_scale='sd'):\n",
    "    \"\"\"\n",
    "    Self-Consisted Agreement Score as the fixed point of G ↦ P(|e| < (1−G) * S_y) − G.\n",
    "    S_y defaults to std(y_true) with robust fallback to MAD.\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    e = np.abs(y_true - y_pred)\n",
    "\n",
    "    # Handle trivial cases first\n",
    "    if np.allclose(e, 0):\n",
    "        return 1.0\n",
    "\n",
    "    S = _scale_y(y_true, prefer=prefer_scale)\n",
    "\n",
    "    def f(G):\n",
    "        thr = (1.0 - G) * S\n",
    "        # If thr <= 0, P(|e| < thr) = 0 unless there are exact zeros:\n",
    "        if thr <= 0:\n",
    "            return (np.mean(e < 0.0)) - G \n",
    "        return np.mean(e < thr) - G\n",
    "\n",
    "    # Ensure a valid bracket on [0,1]\n",
    "    f0 = f(0.0)      # = P(|e| < S) ≥ 0\n",
    "    f1 = f(1.0)      # = P(|e| < 0) - 1 ≈ -1\n",
    "    if f0 < 0:       # extremely pathological; clamp\n",
    "        return 0.0\n",
    "    if f1 > 0:       # only if all e == 0 (handled above), but guard anyway\n",
    "        return 1.0\n",
    "\n",
    "    tau = brentq(f, 0.0, 1.0, xtol=tol)\n",
    "    return float(tau)\n",
    "\n",
    "def TBA(y_true, y_pred, k=0.05, prefer_scale='sd'):\n",
    "    \"\"\"\n",
    "    Tolerance-based Acurracy (TBA) at tolerance k  -> A(k) using sigma_ref from y_true (std by default, MAD fallback).\n",
    "    Uses strict '<'.\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    e = np.abs(y_true - y_pred)\n",
    "    sigma_ref = _scale_y(y_true, prefer=prefer_scale)\n",
    "    thr = k * sigma_ref\n",
    "    # if thr <= 0, accuracy is 0 unless all errors are 0\n",
    "    if thr <= 0:\n",
    "        return float(np.mean(e < 0.0))\n",
    "    return float(np.mean(e < thr))\n",
    "\n",
    "def compute_metrics(y_true, y_pred, ks=(0.05, 0.1, 0.2, 0.5), prefer_scale=\"sd\"):\n",
    "    out = {\"SCAS\": SCAS(y_true, y_pred, prefer_scale=prefer_scale), \"R2\": r2_score(y_true, y_pred)}\n",
    "    for k in ks:\n",
    "        out[f\"A({k})\"] = TBA(y_true, y_pred, k=k, prefer_scale=prefer_scale)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f790b-1a34-4eac-b8be-d3b71fcc0114",
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE = {\n",
    "    \"SCAS\":    dict(color=\"#d62728\", marker=\"o\", linestyle=\"-\",  label=\"SCAS\"),     # red\n",
    "    \"R2\":      dict(color=\"#000000\", marker=\"x\", linestyle=\"-\",  label=\"R²\"),       # black\n",
    "    \"A(0.05)\": dict(color=\"#6a3d9a\", marker=\"^\", linestyle=\"--\", label=\"A(0.05)\"),  # purple\n",
    "    \"A(0.1)\":  dict(color=\"#1f78b4\", marker=\"v\", linestyle=\"--\", label=\"A(0.1)\"),   # blue\n",
    "    \"A(0.2)\":  dict(color=\"#008080\", marker=\"D\", linestyle=\"--\", label=\"A(0.2)\"),   # teal\n",
    "    \"A(0.5)\":  dict(color=\"#4c9bdc\", marker=\"P\", linestyle=\"--\", label=\"A(0.5)\"),   # light\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3350856-7577-4e4f-99af-6c7d66022c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b290231-3c73-438d-b832-aa7149fb18ac",
   "metadata": {},
   "source": [
    "# Experiment 1: Single outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156bc556-ff49-423a-afd7-3ee033cf87d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Sine function data\n",
    "x = np.linspace(0, 2*np.pi, 20)\n",
    "y_true = np.sin(x)\n",
    "\n",
    "sd = np.std(y_true)\n",
    "\n",
    "# Add a slight noise\n",
    "y = np.sin(x + np.random.uniform(-0.1*sd, 0.1*sd, size=len(x)))\n",
    "y[10] += 10*sd  # introduce outlier\n",
    "\n",
    "# Real world Brownlee's stackloss dataset\n",
    "import statsmodels.api as sm\n",
    "data = sm.datasets.stackloss.load_pandas().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0742386a-4f6d-4869-bad0-101cf72421db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tau finding\n",
    "def find_tau(y_true, y_sim, name=None):\n",
    "    residuals = np.abs(y_true - y_sim)\n",
    "    sigma = np.std(y_true)\n",
    "    N = len(residuals)\n",
    "    \n",
    "    def f_tau(tau, residuals, sigma):\n",
    "        threshold = (1 - tau) * sigma\n",
    "        return np.mean(residuals < threshold)\n",
    "    \n",
    "    # Generate values of tau in [0, 1]\n",
    "    tau_values = np.linspace(0, 1, 500)\n",
    "    f_values = [f_tau(tau, residuals, sigma) for tau in tau_values]\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(tau_values, f_values, label=r'$f(\\tau)$')\n",
    "    plt.plot(tau_values, tau_values, 'r--', label=r'$\\tau$ (identity line)')\n",
    "    plt.xlabel(r'$\\tau$', fontsize=14)\n",
    "    plt.ylabel(r'$f(\\tau)$', fontsize=14)\n",
    "    plt.title(f'Fixed-Point Visualization - {name}', fontsize=16)\n",
    "    plt.legend(fontsize=16)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "    plt.grid(False)\n",
    "    plt.savefig(f'SCAS_{name}_Latest SCAS find')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80e3201-034b-4915-b5fb-ffaef24af745",
   "metadata": {},
   "source": [
    "## 1a) Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c4a61-39bf-4c44-8d7f-fd32cada3efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a slight noise\n",
    "y = np.sin(x + np.random.uniform(-0.1*sd, 0.1*sd, size=len(x)))\n",
    "y[10] += 3*sd  # introduce outlier\n",
    "y_sim = y\n",
    "\n",
    "plt.plot(x, y, label='simulated signal')\n",
    "plt.plot(x, y_true, linestyle='dashed', label='clean signal')\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('x')\n",
    "plt.title('Synthetic dataset')\n",
    "plt.legend()\n",
    "plt.savefig('New dataset Figure - Sine function with an outlier - 3S.png', dpi=900)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7b1e79-4f5f-4230-bf8d-3f15ce70c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_tau(y_true, y_sim, name='Synthetic dataset - sin(x)')\n",
    "print(f'SCAS: {SCAS(y_true, y_sim)}')\n",
    "print(f'r2 score: {r2_score(y_true, y_sim)}')\n",
    "for k in [0.05, 0.1, 0.2, 0.5]:\n",
    "    print(f'A({k}): {TBA(y_true, y_sim)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96675bda-9627-4396-9b14-445fcca8e52e",
   "metadata": {},
   "source": [
    "## 1b) Real-world data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851fa753-a3ce-42e3-8f9b-d1041c94edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 21)\n",
    "\n",
    "for col in data.columns:\n",
    "    y_true = data[col]\n",
    "    sd = np.std(y_true)\n",
    "    \n",
    "    y_sim = y_true + np.random.uniform(-0.1*sd, 0.1*sd, size=len(x))\n",
    "    y_sim[7] = y_true[7] + 3*sd\n",
    "    plt.plot(x, y_sim, label='simulated signal')\n",
    "    plt.plot(x, y_true, linestyle='dashed', label='clean signal')\n",
    "    plt.ylabel(col)\n",
    "    plt.xlabel('time step')\n",
    "    plt.title('Real-world dataset')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'New dataset Figure - {col} dataset with an outlier', dpi=900)\n",
    "    plt.show()\n",
    "\n",
    "    find_tau(y_true, y_sim, name=f'Synthetic dataset - {col}')\n",
    "    print(f'SCAS: {SCAS(y_true, y_sim)}')\n",
    "    print(f'r2 score: {r2_score(y_true, y_sim)}')\n",
    "    for k in [0.05, 0.1, 0.2, 0.5]:\n",
    "        print(f'A({k}): {TBA(y_true, y_sim)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c320344-611c-487c-9554-091cb6dcd3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "897a0ded-119a-4a5b-b068-21e5ce79d047",
   "metadata": {},
   "source": [
    "# Experiment 2: Contamination Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14afab0d-8470-46c7-8d83-147026dcb117",
   "metadata": {},
   "outputs": [],
   "source": [
    "_rng = np.random.default_rng(123)\n",
    "\n",
    "# --------------------------\n",
    "# Synthetic data generators\n",
    "# --------------------------\n",
    "def sample_clean_signal(dist, n, rng=None):\n",
    "    \"\"\"\n",
    "    Draw y from the specified distribution. \n",
    "    \"\"\"\n",
    "    rng = _rng if rng is None else rng\n",
    "    if dist == \"normal\":\n",
    "        return rng.normal(loc=0.0, scale=1.0, size=n)\n",
    "    if dist == \"t3\":\n",
    "        # centre at 0; variance finite (3/(3-2)) so this is heavy-tailed\n",
    "        return rng.standard_t(df=3, size=n)\n",
    "    if dist == \"laplace\":\n",
    "        return rng.laplace(loc=0.0, scale=1.0, size=n)  # unit sd\n",
    "    raise ValueError(\"Unknown dist\")\n",
    "\n",
    "def draw_noise(kind, n, rng=None):\n",
    "    if kind == \"gauss\":\n",
    "        return rng.normal(size=n)\n",
    "    if kind == \"laplace\":\n",
    "        return rng.laplace(scale=1/np.sqrt(2), size=n)  # unit sd\n",
    "    raise ValueError(\"unknown noise\")\n",
    "\n",
    "# --------------------------\n",
    "# Contamination mechanism\n",
    "# --------------------------\n",
    "def contaminate_predictions(y_true, y_pred_clean, contam_frac, noise_kind, scale_mult, rng,\n",
    "                            prefer_scale=\"sd\"):\n",
    "    \"\"\"\n",
    "    Contaminate a fraction of points by adding noise ~ (scale_mult * sigma_ref) * D,\n",
    "    where D is unit-sd Gaussian or Laplace. sigma_ref is computed from y_true.\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred_clean = np.asarray(y_pred_clean)\n",
    "\n",
    "    n = len(y_true)\n",
    "    m = int(np.floor(contam_frac * n))\n",
    "    if contam_frac > 0 and m == 0:\n",
    "        m = 1\n",
    "    idx = np.arange(n) if contam_frac >= 1.0 else rng.choice(n, size=m, replace=False)\n",
    "\n",
    "    sigma_ref = _scale_y(y_true, prefer=prefer_scale)\n",
    "    noise = scale_mult * sigma_ref * draw_noise(noise_kind, len(idx), rng)\n",
    "\n",
    "    y_pred = y_pred_clean.copy()\n",
    "    y_pred[idx] = y_pred[idx] + noise\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c420d73-cb11-4685-b09d-2312e38b5607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b92079a8-7a2f-4e59-bdf9-4b4751d8a040",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd80589e-4faa-4e06-8aaa-e4287226a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Experiment A: Synthetic dataset\n",
    "# --------------------------\n",
    "def run_contamination_synthetic(\n",
    "    dists=(\"normal\", \"t3\", \"laplace\"),\n",
    "    Ns=(20, 50, 100),\n",
    "    contam_fracs=(0.10, 0.50, 1.00),\n",
    "    noise_kinds=(\"gauss\", \"laplace\"),\n",
    "    scales=(0.5, 1.0, 1.5, 2.0),\n",
    "    R=1000,\n",
    "    seed=42,\n",
    "    ks=(0.05, 0.1, 0.2, 0.5),\n",
    "):\n",
    "    rng0 = np.random.default_rng(seed)\n",
    "    rows = []\n",
    "\n",
    "    for dist in dists:\n",
    "        for N in Ns:\n",
    "            for contam in contam_fracs:\n",
    "                for nk in noise_kinds:\n",
    "                    for sc in scales:\n",
    "                        for _ in range(R):\n",
    "                            rng = np.random.default_rng(rng0.integers(0, 2**31 - 1))\n",
    "                            y_true = sample_clean_signal(dist, N, rng)\n",
    "\n",
    "                            # baseline: perfect prediction, then contaminate a fraction\n",
    "                            y_pred_clean = y_true.copy()\n",
    "                            y_pred = contaminate_predictions(\n",
    "                                y_true, y_pred_clean,\n",
    "                                contam_frac=contam, noise_kind=nk, scale_mult=sc,\n",
    "                                rng=rng, prefer_scale=\"sd\"\n",
    "                            )\n",
    "\n",
    "                            mets = compute_metrics(y_true, y_pred, ks=ks, prefer_scale=\"sd\")\n",
    "                            rows.append({\n",
    "                                \"dataset\": \"synthetic\",\n",
    "                                \"dist\": dist,\n",
    "                                \"N\": N,\n",
    "                                \"contam_frac\": contam,\n",
    "                                \"contam_noise\": nk,\n",
    "                                \"scale_mult\": sc,\n",
    "                                **mets\n",
    "                            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# --------------------------\n",
    "# Experiment B: Stackloss (real-world dataset)\n",
    "# --------------------------\n",
    "def load_stackloss():\n",
    "    try:\n",
    "        import statsmodels.api as sm\n",
    "        data = sm.datasets.stackloss.load_pandas().data\n",
    "        return {\n",
    "            \"stackloss\": data[\"STACKLOSS\"].to_numpy(),\n",
    "            \"air_flow\":  data[\"AIRFLOW\"].to_numpy(),\n",
    "            \"water_temp\": data[\"WATERTEMP\"].to_numpy(),\n",
    "            \"acid_conc\": data[\"ACIDCONC\"].to_numpy(),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\n",
    "            \"Could not load stackloss via statsmodels. \"\n",
    "            \"Install statsmodels (pip install statsmodels) or provide the dataset manually.\"\n",
    "        ) from e\n",
    "\n",
    "def run_contamination_stackloss(\n",
    "    contam_fracs=(0.10, 0.50, 1.00),\n",
    "    noise_kinds=(\"gauss\", \"laplace\"),\n",
    "    scales=(0.5, 1.0, 1.5, 2.0),\n",
    "    R=1000,\n",
    "    seed=123,\n",
    "    ks=(0.05, 0.1, 0.2, 0.5),\n",
    "):\n",
    "    signals = load_stackloss()\n",
    "    rng0 = np.random.default_rng(seed)\n",
    "    rows = []\n",
    "\n",
    "    for signal_name, y_true in signals.items():\n",
    "        for contam in contam_fracs:\n",
    "            for nk in noise_kinds:\n",
    "                for sc in scales:\n",
    "                    for _ in range(R):\n",
    "                        rng = np.random.default_rng(rng0.integers(0, 2**31 - 1))\n",
    "                        y_pred = contaminate_predictions(\n",
    "                            y_true, y_true.copy(),\n",
    "                            contam_frac=contam, noise_kind=nk, scale_mult=sc,\n",
    "                            rng=rng, prefer_scale=\"sd\"\n",
    "                        )\n",
    "                        mets = compute_metrics(y_true, y_pred, ks=ks, prefer_scale=\"sd\")\n",
    "                        rows.append({\n",
    "                            \"dataset\": \"stackloss\",\n",
    "                            \"signal\": signal_name,\n",
    "                            \"contam_frac\": contam,\n",
    "                            \"contam_noise\": nk,\n",
    "                            \"scale_mult\": sc,\n",
    "                            **mets\n",
    "                        })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1771b0f-d44e-4571-a65a-ab4489cd68b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ks = [0.05, 0.1, 0.2, 0.5]\n",
    "\n",
    "df_syn = run_contamination_synthetic(\n",
    "    dists=(\"normal\", \"t3\", \"laplace\"),\n",
    "    Ns=(20, 50, 100),\n",
    "    contam_fracs=(0.10, 0.50, 1.00),\n",
    "    noise_kinds=(\"gauss\", \"laplace\"),\n",
    "    scales=(0.5, 1.0, 1.5, 2.0),\n",
    "    R=1000,\n",
    "    seed=42,\n",
    "    ks=Ks,\n",
    ")\n",
    "\n",
    "df_stk = run_contamination_stackloss(\n",
    "    contam_fracs=(0.10, 0.50, 1.00),\n",
    "    noise_kinds=(\"gauss\", \"laplace\"),\n",
    "    scales=(0.5, 1.0, 1.5, 2.0),\n",
    "    R=1000, \n",
    "    seed=123,\n",
    "    ks=Ks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5c4ccc-c2ed-404c-99f8-8254571ada96",
   "metadata": {},
   "source": [
    "## Generate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8205794-75c5-4c9c-9fa2-05a0069cd46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_comparison_curves(\n",
    "    df, dataset=\"synthetic\", outdir=\"final_results_scas/curves\",\n",
    "    metrics=(\"R2\", \"SCAS\", \"A(0.05)\", \"A(0.1)\", \"A(0.2)\" ,\"A(0.5)\"),\n",
    "    Ns=None, contam_fracs=(0.10, 0.50, 1.00), noise_kinds=(\"gauss\", \"laplace\"),\n",
    "):\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    if dataset == \"synthetic\":\n",
    "        if Ns is None:\n",
    "            Ns = sorted(df[\"N\"].unique())\n",
    "        dists = sorted(df[\"dist\"].unique())\n",
    "        subsets = [\n",
    "            (df.query(f\"dist=='{d}' & N=={int(N)} & contam_frac=={cf} & contam_noise=='{nk}'\"),\n",
    "             f\"Synthetic ({d}), N={N}, {int(100*cf)}% contam, {nk}\",\n",
    "             f\"SYN_CURVE_{d}_N{N}_{int(100*cf)}pct_{nk}.png\")\n",
    "            for d in dists for N in Ns for nk in noise_kinds for cf in contam_fracs\n",
    "        ]\n",
    "    else:\n",
    "        signals = sorted(df[\"signal\"].unique())\n",
    "        subsets = [\n",
    "            (df.query(f\"signal=='{s}' & contam_frac=={cf} & contam_noise=='{nk}'\"),\n",
    "             f\"Stackloss ({s}), {int(100*cf)}% contam, {nk}\",\n",
    "             f\"STK_CURVE_{s}_{int(100*cf)}pct_{nk}.png\")\n",
    "            for s in signals for nk in noise_kinds for cf in contam_fracs\n",
    "        ]\n",
    "    for sub, title, fname in subsets:\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        for m in metrics:\n",
    "            if m not in sub.columns:\n",
    "                continue\n",
    "            med = sub.groupby(\"scale_mult\")[m].median().reset_index().sort_values(\"scale_mult\")\n",
    "            st = STYLE.get(m, {\"color\": \"gray\", \"marker\": \"o\", \"linestyle\": \"--\", \"label\": m})\n",
    "            ax.plot(med[\"scale_mult\"], med[m], marker=st[\"marker\"], linestyle=st[\"linestyle\"],\n",
    "                    color=st[\"color\"], label=st[\"label\"])\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"Contamination scale (× σ_ref)\")\n",
    "        ax.set_ylabel(\"Median metric\")\n",
    "        ax.set_ylim(-1, 1)\n",
    "        ax.grid(False)\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(os.path.join(outdir, fname), dpi=1200)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526d13b6-055e-48de-aac8-c7db8f93dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_boxplots(\n",
    "    df, dataset=\"synthetic\", outdir=\"final_results_scas/boxplots\",\n",
    "    metrics=(\"R2\", \"SCAS\", \"A(0.05)\", \"A(0.1)\", \"A(0.2)\" ,\"A(0.5)\"),\n",
    "    Ns=None, contam_fracs=(0.10, 0.50, 1.0), scales=(2.0,), noise_kinds=(\"gauss\", \"laplace\"),\n",
    "):\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    if dataset == \"synthetic\":\n",
    "        if Ns is None:\n",
    "            Ns = sorted(df[\"N\"].unique())\n",
    "        dists = sorted(df[\"dist\"].unique())\n",
    "        subsets = [\n",
    "            (df.query(f\"dist=='{d}' & N=={int(N)} & contam_frac=={cf} & contam_noise=='{nk}' & scale_mult=={sc}\"),\n",
    "             f\"Synthetic ({d}), N={N}, {int(100*cf)}% contam, {sc}σ, {nk}\",\n",
    "             f\"SYN_BOX_{d}_N{N}_{int(100*cf)}pct_{sc}sig_{nk}.png\")\n",
    "            for d in dists for N in Ns for nk in noise_kinds for cf in contam_fracs for sc in scales\n",
    "        ]\n",
    "    else:\n",
    "        signals = sorted(df[\"signal\"].unique())\n",
    "        subsets = [\n",
    "            (df.query(f\"signal=='{s}' & contam_frac=={cf} & contam_noise=='{nk}' & scale_mult=={sc}\"),\n",
    "             f\"Stackloss ({s}), {int(100*cf)}% contam, {sc}σ, {nk}\",\n",
    "             f\"STK_BOX_{s}_{int(100*cf)}pct_{sc}sig_{nk}.png\")\n",
    "            for s in signals for nk in noise_kinds for cf in contam_fracs for sc in scales\n",
    "        ]\n",
    "    for sub, title, fname in subsets:\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        data   = [sub[m].values          for m in metrics if m in sub.columns]\n",
    "        labels = [m for m in metrics if m in sub.columns]\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        ax.boxplot(data, labels=labels, showfliers=False)\n",
    "        ax.set_title(title)\n",
    "        ax.set_ylabel(\"Metric value\")\n",
    "        ax.set_ylim(-0.5, 1)\n",
    "        ax.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(os.path.join(outdir, fname), dpi=1200)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14faf25-5ea5-4f79-8365-9bc3a6591481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_heatmaps(\n",
    "    df, dataset=\"synthetic\", outdir=\"final_results_scas/heatmaps\",\n",
    "    metrics = (\"R2\", \"SCAS\", \"A(0.05)\", \"A(0.1)\", \"A(0.2)\" ,\"A(0.5)\"),\n",
    "    Ns=None, contam_fracs=(0.10, 0.50, 1.0), noise_kinds=(\"gauss\", \"laplace\"),\n",
    "):\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    if dataset == \"synthetic\":\n",
    "        if Ns is None:\n",
    "            Ns = sorted(df[\"N\"].unique())\n",
    "        dists = sorted(df[\"dist\"].unique())\n",
    "        subsets = [\n",
    "            (df[(df[\"dist\"]==d) & (df[\"N\"]==N) & (df[\"contam_noise\"]==nk)],\n",
    "             f\"Synthetic ({d}), N={N}, {nk}\",\n",
    "             f\"SYN_HEAT_{{m}}_{d}_N{N}_{nk}.png\")\n",
    "            for d in dists for N in Ns for nk in noise_kinds\n",
    "        ]\n",
    "    else:\n",
    "        signals = sorted(df[\"signal\"].unique())\n",
    "        subsets = [\n",
    "            (df[(df[\"signal\"]==s) & (df[\"contam_noise\"]==nk)],\n",
    "             f\"Stackloss ({s}), {nk}\",\n",
    "             f\"STK_HEAT_{{m}}_{s}_{nk}.png\")\n",
    "            for s in signals for nk in noise_kinds\n",
    "        ]\n",
    "    for sub, title_tpl, fname_tpl in subsets:\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        for m in metrics:\n",
    "            if m not in sub.columns:\n",
    "                continue\n",
    "            piv = (sub.groupby([\"contam_frac\", \"scale_mult\"])[m].median()\n",
    "                      .reset_index()\n",
    "                      .pivot_table(index=\"contam_frac\", columns=\"scale_mult\", values=m, aggfunc=\"first\")\n",
    "                      .sort_index())\n",
    "            fig, ax = plt.subplots(figsize=(6, 4))\n",
    "            im = ax.imshow(piv.values, aspect=\"auto\", origin=\"lower\", cmap=\"viridis\")\n",
    "            ax.set_xticks(np.arange(len(piv.columns)))\n",
    "            ax.set_xticklabels([str(c) for c in piv.columns])\n",
    "            ax.set_yticks(np.arange(len(piv.index)))\n",
    "            ax.set_yticklabels([f\"{int(100*r)}%\" for r in piv.index])\n",
    "            ax.set_xlabel(\"Contamination scale (× σ_ref)\")\n",
    "            ax.set_ylabel(\"Contamination fraction\")\n",
    "            ax.set_title(f\"{title_tpl} — {m}\")\n",
    "            fig.colorbar(im, ax=ax).set_label(m)\n",
    "            plt.tight_layout()\n",
    "            fig.savefig(os.path.join(outdir, fname_tpl.format(m=m)), dpi=1200)\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dbe87d-252f-4942-8b26-1e8ce0cfac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_all_comparison_curves(df_syn, dataset=\"synthetic\")\n",
    "generate_all_comparison_curves(df_stk, dataset=\"stackloss\")\n",
    "\n",
    "generate_all_boxplots(df_syn, dataset=\"synthetic\")\n",
    "generate_all_boxplots(df_stk, dataset=\"stackloss\")\n",
    "\n",
    "# --- EXTENDED DIAGNOSTICS ---\n",
    "generate_all_heatmaps(df_syn, dataset=\"synthetic\")\n",
    "generate_all_heatmaps(df_stk, dataset=\"stackloss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da74d9e-31d3-418c-8dfd-390d1df77100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc12c023-0c7f-4b75-819a-8dd2c8f26cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3f3ecf3-6a1f-49e0-a72b-b5fc695797f3",
   "metadata": {},
   "source": [
    "# Experiment 3: Bias Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e93568-c9c4-4177-b426-fbbbb08399e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_rng = np.random.default_rng(123)\n",
    "\n",
    "def sample_y(dist, n, rng=None):\n",
    "    \"\"\"\n",
    "    Draw y from the specified distribution. \n",
    "    \"\"\"\n",
    "    rng = _rng if rng is None else rng\n",
    "    if dist == \"normal\":\n",
    "        return rng.normal(loc=100.0, scale=10.0, size=n)\n",
    "    if dist == \"laplace\":\n",
    "        return rng.laplace(loc=100.0, scale=10.0, size=n)  # unit sd\n",
    "    raise ValueError(\"Unknown dist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc90aa-152b-4f7c-8ef1-f3428893a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bias_sensitivity(dists=(\"normal\", \"laplace\",\"gamma_k1\",\"cauchy\"),\n",
    "                         N=100, \n",
    "                         bias_levels_add=None,\n",
    "                         bias_levels_mult=None,\n",
    "                         R=1000, seed=42):\n",
    "    rng0 = np.random.default_rng(seed)\n",
    "    rows = []\n",
    "    if bias_levels_add is None:\n",
    "        bias_levels_add = np.linspace(-1, 1, 19)        # multiples of sigma\n",
    "    if bias_levels_mult is None:\n",
    "        bias_levels_mult = np.linspace(0.85, 1.15, 19)  # multiplicative factor\n",
    "\n",
    "    for dist in dists:\n",
    "        for r in range(R):\n",
    "            rng = np.random.default_rng(rng0.integers(0, 2**31-1))\n",
    "            y = sample_y(dist, N, rng=rng)\n",
    "            sigma = np.std(y)\n",
    "\n",
    "            # additive bias\n",
    "            for b in bias_levels_add:\n",
    "                yhat = y + b * sigma\n",
    "                row = {\"dist\": dist, \"N\": N, \"bias_type\": \"add\", \"bias_level\": b}\n",
    "                row[\"SCAS\"] = SCAS(y, yhat)\n",
    "                row[\"R2\"]  = R2(y, yhat)\n",
    "                for k in [0.05, 0.1, 0.2, 0.5]:\n",
    "                    row[f\"A({k})\"] = TBA(y, yhat, k=k)\n",
    "                rows.append(row)\n",
    "\n",
    "            # multiplicative bias\n",
    "            for m in bias_levels_mult:\n",
    "                yhat = m * y\n",
    "                row = {\"dist\": dist, \"N\": N, \"bias_type\": \"mult\", \"bias_level\": m}\n",
    "                row[\"SCAS\"] = SCAS(y, yhat)\n",
    "                row[\"R2\"]  = R2(y, yhat)\n",
    "                for k in [0.05, 0.1, 0.2, 0.5]:\n",
    "                    row[f\"A({k})\"] = TBA(y, yhat, k=k)\n",
    "                rows.append(row)\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e787bab-28c9-4768-99a2-5bbc6d401e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bias_curves(df_bias, dist, bias_type=\"add\"):\n",
    "    metrics = [\"R2\", \"SCAS\", \"A(0.05)\", \"A(0.1)\", \"A(0.2)\" ,\"A(0.5)\"]\n",
    "    sub = df_bias[(df_bias[\"dist\"]==dist) & (df_bias[\"bias_type\"]==bias_type)]\n",
    "    levels = sorted(sub[\"bias_level\"].unique())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    for m in metrics:\n",
    "        med = sub.groupby(\"bias_level\")[m].median().reindex(levels)\n",
    "        st = STYLE.get(m, {\"color\":\"gray\",\"marker\":\"o\",\"linestyle\":\"--\",\"label\":m})\n",
    "        ax.plot(levels, med, marker=st[\"marker\"], linestyle=st[\"linestyle\"],\n",
    "                color=st[\"color\"], label=st[\"label\"])\n",
    "    if bias_type == 'add':\n",
    "        ax.axvline(0, color=\"k\", linestyle=\":\")\n",
    "    if bias_type == 'mul':\n",
    "        ax.axvline(1, color=\"k\", linestyle=\":\")\n",
    "    ax.set_xlabel(\"Bias level\" + (\" (×σ)\" if bias_type==\"add\" else \" (multiplicative factor)\"))\n",
    "    ax.set_ylabel(\"Metric value\")\n",
    "    ax.set_title(f\"Bias sensitivity ({bias_type})\")\n",
    "    ax.legend(ncols=3, fontsize=8, loc='lower center', bbox_to_anchor=(0.5, 0.05))\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.savefig(f'bias_plot_{bias_type}.png', dpi=600)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c65df-9c70-43d4-95ca-d4fdd12a7d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiment\n",
    "df_bias = run_bias_sensitivity(dists=(\"normal\", \"laplace\"))\n",
    "\n",
    "# Additive bias plot\n",
    "plot_bias_curves(df_bias, dist=\"normal\", bias_type=\"add\")\n",
    "\n",
    "# Multiplicative bias plot\n",
    "plot_bias_curves(df_bias, dist=\"normal\", bias_type=\"mult\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a2d579-bc60-484e-8ee3-d93989e9feb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c055a9-9d43-4d07-8594-8c1b6cb5996c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7bc8dd-33ff-4d7b-b645-cf62ea2a9336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
